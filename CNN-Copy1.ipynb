{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import torch\n",
    "from io import open\n",
    "# 一些常量\n",
    "# On windows\n",
    "# dir_train = 'D:/Github/candidate_answer/data/json_train_expt_stop'\n",
    "# dir_test = 'D:/Github/candidate_answer/data/json_test_expt_stop'\n",
    "# dir_embedding = 'D:/nlp_data/sogou_100_nobinary'\n",
    "# On ubuntu\n",
    "dir_train = 'data/json_train_expt_stop2'\n",
    "dir_test = 'data/json_test_expt_stop'\n",
    "dir_embedding = '/home/tuomx/nlp_data/sogou_100_nobinary'\n",
    "\n",
    "embedding_size = 100\n",
    "max_question_words = 23 # 问题最大词数，下同理\n",
    "max_right_answer_words = 824\n",
    "max_wrong_answer_words = 824\n",
    "kernel_size = (3, embedding_size) # 卷积核的size\n",
    "out_channels = 300 # 输出通道数\n",
    "hidden_out = 400 # 隐藏层输出单元数\n",
    "batch_size = 64\n",
    "debug = False\n",
    "\n",
    "log_file = open('log','w',encoding='utf-8',buffering=1)\n",
    "def log(log_inf):\n",
    "    if debug:\n",
    "        print(log_inf)\n",
    "    else:\n",
    "        log_file.write(log_inf)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading enmbedding...\n",
      "finish loading\n"
     ]
    }
   ],
   "source": [
    "# 加载词向量\n",
    "embedding = {}\n",
    "f = open(dir_embedding,\"r\",encoding='utf-8')\n",
    "line = f.readline()\n",
    "line_num = 0\n",
    "print(\"loading enmbedding...\")\n",
    "while line:\n",
    "    try:\n",
    "        content = line.strip(' \\n').split(' ')\n",
    "        assert len(content) == embedding_size + 1\n",
    "        embedding[content[0]] = np.array([float(i) for i in content[1:]])\n",
    "        line = f.readline()\n",
    "        line_num+=1\n",
    "#         print(line_num)\n",
    "    except:\n",
    "        print(content)\n",
    "        break\n",
    "print(\"finish loading\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 创建一个CNN\\\n",
    "\n",
    "# caculate hinge_loss\n",
    "def hinge_loss(s1,s2,t0,batch_size):\n",
    "    # print(s1.size(), s2.size())\n",
    "    loss = Variable(torch.Tensor(1))\n",
    "    loss.data[0] = 0.0\n",
    "    for i in range(batch_size):\n",
    "        if (t0 - s1[i] + s2[i]).data[0] > 0:\n",
    "            loss += t0 - s1[i] + s2[i]\n",
    "        else:\n",
    "            print(\"pos:%f,neg:%f\" % (s1[i].data[0], s2[i].data[0]))\n",
    "    return loss\n",
    "    \n",
    "def get_simple_score(self,question_variable, pos_relation_variable_l, pos_word_variable_l, neg_relation_variable_l, neg_word_variable_l, hn_hidden,cn_hidden):\n",
    "        '''计算一个问题的分数，正例与负例，用max——margin计算\n",
    "        '''\n",
    "        sum_score = 0.0\n",
    "\n",
    "        qr_output = self.qr_model(question_variable,hn_hidden,cn_hidden,self.padding_size)\n",
    "        pos_score_list = []\n",
    "        neg_score_list = []\n",
    "        for pi in range(len(pos_relation_variable_l)):\n",
    "            # self.optimizer.zero_grad()\n",
    "            pos_ar_output = self.ar_model(pos_relation_variable_l[pi],pos_word_variable_l[pi],hn_hidden,cn_hidden,20)\n",
    "            pos_score = F.cosine_similarity(qr_output,pos_ar_output)\n",
    "            pos_score_list.append(pos_score)\n",
    "\n",
    "        for ni in range(len(neg_relation_variable_l)):\n",
    "            # self.optimizer.zero_grad()\n",
    "            neg_ar_output = self.ar_model(neg_relation_variable_l[ni],neg_word_variable_l[ni],hn_hidden,cn_hidden,20)\n",
    "            neg_score = F.cosine_similarity(qr_output,neg_ar_output)\n",
    "            neg_score_list.append(neg_score)\n",
    "\n",
    "        for pos_score in pos_score_list:\n",
    "            for neg_score in neg_score_list:\n",
    "                score = self.max_margin_number - pos_score + neg_score\n",
    "                if score.data[0] <0:\n",
    "                    score = Variable(torch.FloatTensor(1).fill_(0.0))\n",
    "                sum_score += score\n",
    "\n",
    "        return sum_score\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 300, (3,100)) # 保证输出列向量在高度上与X相同\n",
    "        self.conv2 = nn.Conv2d(1, 300, (3,100))\n",
    "        self.conv3 = nn.Conv2d(1, 300, (3,100))\n",
    "\n",
    "        self.pool1 = nn.MaxPool2d(1, max_wrong_answer_words) # 输出是out_channels*1维向量\n",
    "        self.pool2 = nn.MaxPool2d(1, max_question_words)\n",
    "        self.pool3 = nn.MaxPool2d(1, max_right_answer_words)\n",
    "\n",
    "        self.fc1 = nn.Linear(out_channels, hidden_out)\n",
    "        self.fc2 = nn.Linear(out_channels, hidden_out)\n",
    "        self.fc3 = nn.Linear(out_channels, hidden_out)\n",
    "\n",
    "\n",
    "    def forward(self, x1, x2, x3, batch_size):\n",
    "        # x1/x2/x3 分别表示错误答案，问题，正确答案\n",
    "#         x1 = self.pool1(F.tanh(self.conv1(x1)))\n",
    "#         x2 = self.pool2(F.tanh(self.conv2(x2)))\n",
    "#         x3 = self.pool3(F.tanh(self.conv3(x3)))\n",
    "        # print(\"in forward:\")\n",
    "        # print(\"X:\",x1.size(),x2.size(),x3.size())\n",
    "        x1 = F.tanh(self.conv1(x1))\n",
    "        x2 = F.tanh(self.conv2(x2))\n",
    "        x3 = F.tanh(self.conv3(x3))\n",
    "        #print(\"conv1:\",x1.size(),x2.size(),x3.size())\n",
    "        \n",
    "        x1 = self.pool1(x1)\n",
    "        x2 = self.pool2(x2)\n",
    "        x3 = self.pool3(x3)\n",
    "        #print(\"pool:\",x1.size(),x2.size(),x3.size())\n",
    "        \n",
    "        x1 = F.tanh(x1)\n",
    "        x2 = F.tanh(x2)\n",
    "        x3 = F.tanh(x3)\n",
    "\n",
    "        neg_cosine = F.cosine_similarity(x1,x2)\n",
    "        pos_cosine = F.cosine_similarity(x2,x3)\n",
    "        #print(neg_cosine, pos_cosine)\n",
    "\n",
    "        return hinge_loss(pos_cosine, neg_cosine, 2, batch_size), pos_cosine, neg_cosine\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-f9792e2f5ba3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     45\u001b[0m                 \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m                 \u001b[0;31m# forward + backward + optimize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m                 \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpos_cosine\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mneg_cosine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m                     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-33-66d05688449e>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x1, x2, x3, batch_size)\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;31m# print(\"in forward:\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;31m# print(\"X:\",x1.size(),x2.size(),x3.size())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0mx1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m         \u001b[0mx2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0mx3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mtanh\u001b[0;34m(input)\u001b[0m\n\u001b[1;32m    539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_autograd_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTanh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/autograd/_functions/pointwise.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx, i, inplace)\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_for_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 开始训练\n",
    "def get_sentence_embedding(s,out_size):\n",
    "    arr = []\n",
    "    for word in s:\n",
    "        if word in embedding:\n",
    "            arr.append(embedding[word])\n",
    "        else:\n",
    "            arr.append([random.uniform(-1,1) for i in range(embedding_size)])\n",
    "    if len(arr) < out_size: # 补零\n",
    "        append_arr = [0.0 for i in range(embedding_size)]\n",
    "        for j in range(out_size - len(arr)):\n",
    "            arr.append(append_arr)\n",
    "    return [arr]\n",
    "\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "f = open(dir_train,'r',encoding='utf-8')\n",
    "data = json.loads(f.read()) # 8768 quesions(except 4 questions which don't have the right answer)\n",
    "count_step = 0\n",
    "for epoch in range(2):  # loop over the dataset multiple times\n",
    "    f = open(dir_train)\n",
    "    running_loss = 0.0\n",
    "    batch = [[] for i in range(3)]\n",
    "    for id in data:\n",
    "        # stop early\n",
    "#         if count_step == 5000:\n",
    "#             print(\"finish training\")\n",
    "#             break\n",
    "        \n",
    "        # get the inputs\n",
    "        question_ebd = get_sentence_embedding(data[id]['question'], max_question_words)\n",
    "        right_answer_ebd = get_sentence_embedding(data[id]['right_answer'][0], max_right_answer_words)\n",
    "        for wrong_answer in data[id]['wrong_answer']:\n",
    "            wrong_answer_ebd = get_sentence_embedding(wrong_answer, max_wrong_answer_words)\n",
    "            batch[0].append(wrong_answer_ebd)\n",
    "            batch[1].append(question_ebd)\n",
    "            batch[2].append(right_answer_ebd)\n",
    "            if len(batch[0]) == batch_size:\n",
    "                # wrap them in Variable\n",
    "                # assert(batch[0])\n",
    "        \n",
    "                x1 = Variable(torch.from_numpy(np.array(batch[0])).float())\n",
    "                x2 = Variable(torch.from_numpy(np.array(batch[1])).float())\n",
    "                x3 = Variable(torch.from_numpy(np.array(batch[2])).float())\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "                # forward + backward + optimize\n",
    "                loss,pos_cosine,neg_cosine = net(x1, x2, x3, batch_size)\n",
    "                if loss.data[0] != 0.0:\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                    # print statistics\n",
    "                    count_step += 1\n",
    "                    running_loss += loss.data[0]\n",
    "    #                print(\"Epoch:%d Step:%d: Loss:%f\" % (epoch, count_step, loss.data[0]))\n",
    "                    if count_step % 200 == 199:    # print every 2000 mini-batches\n",
    "                        print('[%d, %5d] loss: %.3f' %\n",
    "                              (epoch + 1, count_step + 1, running_loss / 200))\n",
    "                        running_loss = 0.0\n",
    "                # clear batch\n",
    "                batch = [[] for i in range(3)]\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start test...\n",
      "rank:25\n",
      "rank:6\n",
      "rank:10\n",
      "rank:5\n",
      "rank:4\n",
      "rank:7\n",
      "rank:7\n",
      "rank:7\n",
      "rank:9\n",
      "rank:6\n",
      "rank:9\n",
      "rank:10\n",
      "rank:2\n",
      "rank:26\n",
      "rank:8\n",
      "rank:20\n",
      "rank:15\n",
      "rank:15\n",
      "rank:7\n",
      "rank:26\n",
      "rank:12\n",
      "rank:3\n",
      "rank:5\n",
      "rank:16\n",
      "rank:30\n",
      "rank:4\n",
      "rank:4\n",
      "rank:1\n",
      "rank:1\n",
      "rank:27\n",
      "rank:7\n",
      "rank:12\n",
      "rank:6\n",
      "rank:21\n",
      "rank:12\n",
      "rank:6\n",
      "rank:2\n",
      "rank:7\n",
      "rank:25\n",
      "rank:17\n",
      "rank:13\n",
      "rank:15\n",
      "rank:9\n",
      "rank:18\n",
      "rank:20\n",
      "rank:19\n",
      "rank:9\n",
      "rank:17\n",
      "rank:2\n",
      "rank:21\n",
      "rank:14\n",
      "rank:1\n",
      "rank:11\n",
      "rank:2\n",
      "rank:7\n",
      "rank:1\n",
      "rank:3\n",
      "rank:9\n",
      "rank:20\n",
      "rank:1\n",
      "rank:19\n",
      "rank:7\n",
      "rank:28\n",
      "rank:3\n",
      "rank:9\n",
      "rank:18\n",
      "rank:3\n",
      "rank:24\n",
      "rank:17\n",
      "rank:10\n",
      "rank:12\n",
      "rank:17\n",
      "rank:20\n",
      "rank:12\n",
      "rank:27\n",
      "rank:21\n",
      "rank:19\n",
      "rank:12\n",
      "rank:7\n",
      "rank:7\n",
      "rank:7\n",
      "rank:5\n",
      "rank:23\n",
      "rank:5\n",
      "rank:5\n",
      "rank:15\n",
      "rank:5\n",
      "rank:14\n",
      "rank:15\n",
      "rank:6\n",
      "rank:29\n",
      "rank:1\n",
      "rank:3\n",
      "rank:28\n",
      "rank:1\n",
      "rank:3\n",
      "rank:7\n",
      "rank:18\n",
      "rank:10\n",
      "rank:7\n",
      "rank:1\n",
      "rank:11\n",
      "rank:20\n",
      "rank:15\n",
      "rank:12\n",
      "rank:5\n",
      "rank:6\n",
      "rank:11\n",
      "rank:3\n",
      "rank:9\n",
      "rank:27\n",
      "rank:15\n",
      "rank:13\n",
      "rank:4\n",
      "rank:13\n",
      "rank:25\n",
      "rank:9\n",
      "rank:1\n",
      "rank:4\n",
      "rank:4\n",
      "rank:22\n",
      "rank:1\n",
      "rank:8\n",
      "rank:10\n",
      "rank:15\n",
      "rank:24\n",
      "rank:7\n",
      "rank:7\n",
      "rank:17\n",
      "rank:24\n",
      "rank:5\n",
      "rank:11\n",
      "rank:3\n",
      "rank:3\n",
      "rank:6\n",
      "rank:2\n",
      "rank:4\n",
      "rank:4\n",
      "rank:2\n",
      "rank:1\n",
      "rank:20\n",
      "rank:12\n",
      "rank:27\n",
      "rank:6\n",
      "rank:7\n",
      "rank:17\n",
      "rank:21\n",
      "rank:6\n",
      "rank:25\n",
      "rank:8\n",
      "rank:2\n",
      "rank:11\n",
      "rank:8\n",
      "rank:16\n",
      "rank:2\n",
      "rank:2\n",
      "rank:24\n",
      "rank:14\n",
      "rank:18\n",
      "rank:1\n",
      "rank:9\n",
      "rank:14\n",
      "rank:2\n",
      "rank:11\n",
      "rank:13\n",
      "rank:18\n",
      "rank:23\n",
      "rank:22\n",
      "rank:2\n",
      "rank:23\n",
      "rank:10\n",
      "rank:4\n",
      "rank:18\n",
      "rank:1\n",
      "rank:13\n",
      "rank:25\n",
      "rank:16\n",
      "rank:9\n",
      "rank:1\n",
      "rank:10\n",
      "rank:16\n",
      "rank:19\n",
      "rank:10\n",
      "rank:12\n",
      "rank:4\n",
      "rank:14\n",
      "rank:7\n",
      "rank:17\n",
      "rank:15\n",
      "rank:9\n",
      "rank:23\n",
      "rank:1\n",
      "rank:10\n",
      "rank:15\n",
      "rank:2\n",
      "rank:1\n",
      "rank:1\n",
      "rank:17\n",
      "rank:16\n",
      "rank:20\n",
      "rank:28\n",
      "rank:8\n",
      "rank:4\n",
      "rank:15\n",
      "rank:3\n",
      "rank:7\n",
      "rank:20\n",
      "rank:8\n",
      "rank:16\n",
      "rank:3\n",
      "rank:4\n",
      "rank:5\n",
      "rank:7\n",
      "rank:2\n",
      "rank:1\n",
      "rank:1\n",
      "rank:1\n",
      "rank:14\n",
      "rank:30\n",
      "rank:27\n",
      "rank:8\n",
      "rank:5\n",
      "rank:3\n",
      "rank:15\n",
      "rank:5\n",
      "rank:1\n",
      "rank:9\n",
      "rank:16\n",
      "rank:11\n",
      "rank:2\n",
      "rank:30\n",
      "rank:16\n",
      "rank:14\n",
      "rank:5\n",
      "rank:5\n",
      "rank:16\n",
      "rank:13\n",
      "rank:2\n",
      "rank:18\n",
      "rank:8\n",
      "rank:4\n",
      "rank:2\n",
      "rank:11\n",
      "rank:5\n",
      "rank:12\n",
      "rank:7\n",
      "rank:22\n",
      "rank:9\n",
      "rank:7\n",
      "rank:1\n",
      "rank:13\n",
      "rank:3\n",
      "rank:11\n",
      "rank:23\n",
      "rank:9\n",
      "rank:1\n",
      "rank:6\n",
      "rank:10\n",
      "rank:11\n",
      "rank:1\n",
      "rank:2\n",
      "rank:1\n",
      "rank:4\n",
      "rank:5\n",
      "rank:3\n",
      "rank:3\n",
      "rank:19\n",
      "rank:21\n",
      "rank:1\n",
      "rank:9\n",
      "rank:24\n",
      "rank:1\n",
      "rank:5\n",
      "rank:13\n",
      "rank:2\n",
      "rank:2\n",
      "rank:12\n",
      "rank:10\n",
      "rank:3\n",
      "rank:21\n",
      "rank:20\n",
      "rank:14\n",
      "rank:14\n",
      "rank:1\n",
      "rank:8\n",
      "rank:21\n",
      "rank:1\n",
      "rank:7\n",
      "rank:1\n",
      "rank:26\n",
      "rank:24\n",
      "rank:9\n",
      "rank:13\n",
      "rank:26\n",
      "rank:21\n",
      "rank:27\n",
      "rank:15\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-12cb69ddf94c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0mx2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0mx3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mneg_score\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mneg_cosine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m             \u001b[0;31m# print(x1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0;31m#print(pos_score.data[0],neg_score.data[0])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-66d05688449e>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x1, x2, x3, batch_size)\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0mx1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0mx2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0mx3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m         \u001b[0;31m#print(\"conv1:\",x1.size(),x2.size(),x3.size())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mtanh\u001b[0;34m(input)\u001b[0m\n\u001b[1;32m    539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_autograd_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTanh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/autograd/_functions/pointwise.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx, i, inplace)\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_for_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# test\n",
    "print('start test...')\n",
    "f = open(dir_test,'r',encoding='utf-8')\n",
    "test_data = json.loads(f.read())\n",
    "\n",
    "MRR = 0\n",
    "count_right_answer = 0\n",
    "for id in test_data:\n",
    "    # get the inputs\n",
    "    question_ebd = get_sentence_embedding(test_data[id]['question'], max_question_words)\n",
    "    \n",
    "    for right_answer in data[id]['right_answer']:\n",
    "        right_answer_ebd = get_sentence_embedding(right_answer, max_right_answer_words)\n",
    "        rank = 1 # rank of right answer in all answers\n",
    "        no_pos_score = True # tag to help caculate right score\n",
    "        for wrong_answer in data[id]['wrong_answer']:\n",
    "            batch = [[] for i in range(3)]\n",
    "            wrong_answer_ebd = get_sentence_embedding(wrong_answer, max_wrong_answer_words)\n",
    "            batch[0].append(wrong_answer_ebd)\n",
    "            batch[1].append(question_ebd)\n",
    "            batch[2].append(right_answer_ebd)\n",
    "\n",
    "            # print(x1.size(),x2.size(),x3.size())\n",
    "            if no_pos_score:\n",
    "                x1 = Variable(torch.from_numpy(np.array(batch[0])).float())\n",
    "                x2 = Variable(torch.from_numpy(np.array(batch[1])).float())\n",
    "                x3 = Variable(torch.from_numpy(np.array(batch[2])).float())\n",
    "                loss,pos_score,neg_cosine = net(x1,x2,x3,1)\n",
    "                no_pos_score = False\n",
    "            x1 = Variable(torch.from_numpy(np.array(batch[0])).float())\n",
    "            x2 = Variable(torch.from_numpy(np.array(batch[1])).float())\n",
    "            x3 = Variable(torch.from_numpy(np.array(batch[2])).float())\n",
    "            loss,neg_score,neg_cosine = net(x3,x2,x1,1)\n",
    "            # print(x1)\n",
    "            #print(pos_score.data[0],neg_score.data[0])\n",
    "            if pos_score.data[0] < neg_score.data[0]:\n",
    "                rank += 1\n",
    "        print(\"rank:%d\" %(rank))\n",
    "        MRR += 1 / rank\n",
    "        count_right_answer += 1\n",
    "        if count_right_answer % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('count_roght_answer:%d; MRR:%f' %\n",
    "                  (count_right_answer, MRR / count_right_answer))\n",
    "MRR /= count_right_answer\n",
    "print(\"Final MRR:%f\" %(MRR))\n",
    "print(\"Finish test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23000256003582398"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MRR / count_right_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = Variable(torch.from_numpy(np.array([1,2,3])).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "\nFound no NVIDIA driver on your system. Please check that you\nhave an NVIDIA GPU and installed a driver from\nhttp://www.nvidia.com/Download/index.aspx",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-54501a7b2d04>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36mcuda\u001b[0;34m(self, device_id, async)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masync\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mCudaTransfer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masync\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/autograd/_functions/tensor.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx, i, device_id, async)\u001b[0m\n\u001b[1;32m    149\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masync\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0masync\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0masync\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0masync\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/_utils.py\u001b[0m in \u001b[0;36m_cuda\u001b[0;34m(self, device, async)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0mnew_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnew_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masync\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_new\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_lazy_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m     \u001b[0m_lazy_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m     \u001b[0;31m# We need this method only for lazy init, so we can remove it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m     \u001b[0;32mdel\u001b[0m \u001b[0m_CudaBase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__new__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m     82\u001b[0m         raise RuntimeError(\n\u001b[1;32m     83\u001b[0m             \"Cannot re-initialize CUDA in forked subprocess. \" + msg)\n\u001b[0;32m---> 84\u001b[0;31m     \u001b[0m_check_driver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_sparse_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_check_driver\u001b[0;34m()\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0mFound\u001b[0m \u001b[0mno\u001b[0m \u001b[0mNVIDIA\u001b[0m \u001b[0mdriver\u001b[0m \u001b[0mon\u001b[0m \u001b[0myour\u001b[0m \u001b[0msystem\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mPlease\u001b[0m \u001b[0mcheck\u001b[0m \u001b[0mthat\u001b[0m \u001b[0myou\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0mhave\u001b[0m \u001b[0man\u001b[0m \u001b[0mNVIDIA\u001b[0m \u001b[0mGPU\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0minstalled\u001b[0m \u001b[0ma\u001b[0m \u001b[0mdriver\u001b[0m \u001b[0;32mfrom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m http://www.nvidia.com/Download/index.aspx\"\"\")\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0;31m# TODO: directly link to the alternative bin that needs install\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: \nFound no NVIDIA driver on your system. Please check that you\nhave an NVIDIA GPU and installed a driver from\nhttp://www.nvidia.com/Download/index.aspx"
     ]
    }
   ],
   "source": [
    "x1.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
